{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import time\n",
    "import os\n",
    "import io\n",
    "\n",
    "from random import seed\n",
    "from random import randint\n",
    "\n",
    "from argparse import ArgumentParser, Namespace\n",
    "import yaml\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# default is to maximize the objectives\n",
    "import time as time\n",
    "import copy\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "\n",
    "# example of a gaussian process surrogate function\n",
    "from math import sin\n",
    "from math import pi\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "from numpy import asarray\n",
    "from numpy.random import normal\n",
    "from numpy.random import uniform\n",
    "from numpy.random import random\n",
    "from numpy import cov\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from warnings import catch_warnings\n",
    "from warnings import simplefilter\n",
    "from autooed.utils.sampling import lhs\n",
    "import random\n",
    "#import xgboost as xgb\n",
    "#from xgboost import XGBRegressor\n",
    "#from xgboost import plot_tree\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "#from sklearn.inspection import partial_dependence, plot_partial_dependence\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "# loocv to manually evaluate the performance of a random forest classifier\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "from scipy.stats import pearsonr as pearsonr\n",
    "from scipy import ndimage, misc\n",
    "import pickle\n",
    "import re\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Descriptors\n",
    "from chainer_chemistry.datasets.molnet import get_molnet_dataset\n",
    "# the package is in the same directory\n",
    "# get Today's date from python!\n",
    "from datetime import datetime\n",
    "from autooed.utils.sampling import lhs\n",
    "from autooed.problem import build_problem\n",
    "from autooed.mobo import build_algorithm\n",
    "from autooed.utils.seed import set_seed\n",
    "from autooed.utils.initialization import generate_random_initial_samples, load_provided_initial_samples\n",
    "from autooed.utils.plot import plot_performance_space, plot_performance_metric\n",
    "from autooed.utils.plot import plot_performance_space_diffcolor\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from arguments import get_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2723764/2777774001.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  RF_print.fit(X, Y)\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__k2__length_scale is close to the specified upper bound 31.622776601683793. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__constant_value is close to the specified lower bound 0.0024787521766663585. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000\n",
      "Accuracy: 1.000\n",
      "10\n",
      "========== Problem Definition ==========\n",
      "# name: printing3d_dlp\n",
      "# n_var: 5\n",
      "# n_obj: 2\n",
      "# n_constr: 3\n",
      "\n",
      "\n",
      "Compiled modules for significant speedup can not be used!\n",
      "https://pymoo.org/installation.html#installation\n",
      "\n",
      "To disable this warning:\n",
      "from pymoo.configuration import Configuration\n",
      "Configuration.show_compile_hint = False\n",
      "\n",
      "========== Algorithm Setup ==========\n",
      "# algorithm: TSEMO\n",
      "# surrogate: GaussianProcess\n",
      "# acquisition: ThompsonSampling\n",
      "# solver: NSGA2\n",
      "# selection: HypervolumeImprovement\n",
      "\n",
      "read X (0, 5)\n",
      "read Y (0,)\n",
      "read X (43, 5)\n",
      "read Y (43, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified upper bound 31.622776601683793. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 4 of parameter k1__k2__length_scale is close to the specified upper bound 31.622776601683793. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__constant_value is close to the specified lower bound 0.0024787521766663585. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__k2__length_scale is close to the specified upper bound 31.622776601683793. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__constant_value is close to the specified lower bound 0.0024787521766663585. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified upper bound 31.622776601683793. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 4 of parameter k1__k2__length_scale is close to the specified upper bound 31.622776601683793. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__constant_value is close to the specified lower bound 0.0024787521766663585. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.54      ]\n",
      " [0.44      ]\n",
      " [0.5       ]\n",
      " [0.        ]\n",
      " [0.36      ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [1.09666667]\n",
      " [0.6       ]\n",
      " [1.14      ]\n",
      " [1.17666667]\n",
      " [1.32      ]\n",
      " [1.4       ]\n",
      " [0.10166667]\n",
      " [1.31      ]\n",
      " [0.        ]\n",
      " [0.46      ]\n",
      " [1.3       ]\n",
      " [0.68      ]\n",
      " [0.        ]\n",
      " [0.66      ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [2.07739673]\n",
      " [2.22847327]]\n",
      "[[0.        ]\n",
      " [0.        ]\n",
      " [1.08198722]\n",
      " [0.24656161]\n",
      " [0.4       ]\n",
      " [0.        ]\n",
      " [0.06      ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.08873701]]\n",
      "[[0.0205599 ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.02      ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.02038041]]\n",
      "[[0.0767865 ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.10108588]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.        ]\n",
      " [0.29703584]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.11279189]]\n",
      "[[0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.02817151]\n",
      " [0.        ]]\n",
      "[[0.       ]\n",
      " [0.       ]\n",
      " [0.       ]\n",
      " [0.       ]\n",
      " [0.       ]\n",
      " [0.       ]\n",
      " [0.       ]\n",
      " [0.0771338]\n",
      " [0.       ]\n",
      " [0.       ]]\n",
      "[[0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.03404936]]\n",
      "[[0.        ]\n",
      " [0.        ]\n",
      " [0.03030985]\n",
      " [0.06600924]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.11992405]]\n",
      "[[0.32774028 0.19852655 0.02       0.15707859 0.18      ]\n",
      " [0.33491417 0.30959377 0.10068622 0.01456503 0.16631611]]\n",
      "8.567938804626465\n",
      "45/50 complete\n",
      "56.207374572753906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 2 of parameter k1__k2__length_scale is close to the specified upper bound 31.622776601683793. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified lower bound 0.03162277660168379. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__constant_value is close to the specified lower bound 0.0024787521766663585. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__constant_value is close to the specified lower bound 0.0024787521766663585. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 2 of parameter k1__k2__length_scale is close to the specified upper bound 31.622776601683793. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified lower bound 0.03162277660168379. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__constant_value is close to the specified lower bound 0.0024787521766663585. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/kianoosh/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__constant_value is close to the specified lower bound 0.0024787521766663585. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 235\u001b[0m\n\u001b[1;32m    233\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    234\u001b[0m \u001b[39m# propose design samples\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m X_next \u001b[39m=\u001b[39m algorithm\u001b[39m.\u001b[39;49moptimize(X, Y, X_busy\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    236\u001b[0m \u001b[39mprint\u001b[39m (X_next)\n\u001b[1;32m    237\u001b[0m \u001b[39mprint\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start)\n",
      "File \u001b[0;32m~/Github/MOBO_RFcons_LCD3D_6monomers/autooed/mobo/mobo.py:94\u001b[0m, in \u001b[0;36mMOBO.optimize\u001b[0;34m(self, X, Y, X_busy, batch_size)\u001b[0m\n\u001b[1;32m     91\u001b[0m Y \u001b[39m=\u001b[39m convert_minimization(Y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj_type)\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39masync_strategy \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m X_busy \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimize(X, Y, batch_size)\n\u001b[1;32m     95\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimize_async(X, Y, X_busy, batch_size)\n",
      "File \u001b[0;32m~/Github/MOBO_RFcons_LCD3D_6monomers/autooed/mobo/mobo.py:109\u001b[0m, in \u001b[0;36mMOBO._optimize\u001b[0;34m(self, X, Y, batch_size)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39macquisition\u001b[39m.\u001b[39mfit(X, Y)\n\u001b[1;32m    108\u001b[0m \u001b[39m# solve surrogate problem\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m X_candidate, Y_candidate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msolver\u001b[39m.\u001b[39;49msolve(X, Y, batch_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49macquisition)\n\u001b[1;32m    111\u001b[0m \u001b[39m# next batch selection\u001b[39;00m\n\u001b[1;32m    112\u001b[0m X_next \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselection\u001b[39m.\u001b[39mselect(X_candidate, Y_candidate, X, Y, batch_size)\n",
      "File \u001b[0;32m~/Github/MOBO_RFcons_LCD3D_6monomers/autooed/mobo/solver/base.py:47\u001b[0m, in \u001b[0;36mSolver.solve\u001b[0;34m(self, X, Y, batch_size, acquisition)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem \u001b[39m=\u001b[39m SurrogateProblem(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreal_problem, acquisition)\n\u001b[1;32m     46\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformation\u001b[39m.\u001b[39mdo(X)\n\u001b[0;32m---> 47\u001b[0m X_candidate, Y_candidate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_solve(X, Y, batch_size)\n\u001b[1;32m     48\u001b[0m X_candidate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformation\u001b[39m.\u001b[39mundo(X_candidate)\n\u001b[1;32m     49\u001b[0m \u001b[39mreturn\u001b[39;00m X_candidate, Y_candidate\n",
      "File \u001b[0;32m~/Github/MOBO_RFcons_LCD3D_6monomers/autooed/mobo/solver/nsga2.py:28\u001b[0m, in \u001b[0;36mNSGA2._solve\u001b[0;34m(self, X, Y, batch_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgo\u001b[39m.\u001b[39minitialization\u001b[39m.\u001b[39msampling \u001b[39m=\u001b[39m X\n\u001b[1;32m     27\u001b[0m \u001b[39m#print ('problem definition in NSGA2 ', self.problem)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m res \u001b[39m=\u001b[39m minimize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproblem, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malgo, (\u001b[39m'\u001b[39;49m\u001b[39mn_gen\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_gen))\n\u001b[1;32m     30\u001b[0m \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39mpop\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m), res\u001b[39m.\u001b[39mpop\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mF\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/pymoo/optimize.py:76\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(problem, algorithm, termination, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         algorithm\u001b[39m.\u001b[39mtermination \u001b[39m=\u001b[39m SingleObjectiveDefaultTermination()\n\u001b[1;32m     75\u001b[0m \u001b[39m# actually execute the algorithm\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m res \u001b[39m=\u001b[39m algorithm\u001b[39m.\u001b[39;49msolve()\n\u001b[1;32m     78\u001b[0m \u001b[39m# store the deep copied algorithm in the result object\u001b[39;00m\n\u001b[1;32m     79\u001b[0m res\u001b[39m.\u001b[39malgorithm \u001b[39m=\u001b[39m algorithm\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/pymoo/model/algorithm.py:208\u001b[0m, in \u001b[0;36mAlgorithm.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m res\u001b[39m.\u001b[39mstart_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    207\u001b[0m \u001b[39m# call the algorithm to solve the problem\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_solve(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproblem)\n\u001b[1;32m    210\u001b[0m \u001b[39m# store the time when the algorithm as finished\u001b[39;00m\n\u001b[1;32m    211\u001b[0m res\u001b[39m.\u001b[39mend_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/pymoo/model/algorithm.py:283\u001b[0m, in \u001b[0;36mAlgorithm._solve\u001b[0;34m(self, problem)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39m# initialize the first population and evaluate it\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_gen \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 283\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize()\n\u001b[1;32m    284\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_optimum()\n\u001b[1;32m    285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_each_iteration()\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/pymoo/algorithms/genetic_algorithm.py:74\u001b[0m, in \u001b[0;36mGeneticAlgorithm._initialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m pop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialization\u001b[39m.\u001b[39mdo(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpop_size, algorithm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[39m# then evaluate using the objective function\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluator\u001b[39m.\u001b[39;49meval(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproblem, pop, algorithm\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[1;32m     76\u001b[0m \u001b[39m# that call is a dummy survival to set attributes that are necessary for the mating selection\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurvival:\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/pymoo/model/evaluator.py:52\u001b[0m, in \u001b[0;36mEvaluator.eval\u001b[0;34m(self, problem, pop, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m# actually evaluate all solutions using the function that can be overwritten\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(I) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_eval(problem, pop[I], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     54\u001b[0m     \u001b[39m# set the feasibility attribute if cv exists\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[39mfor\u001b[39;00m ind \u001b[39min\u001b[39;00m pop[I]:\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/pymoo/model/evaluator.py:71\u001b[0m, in \u001b[0;36mEvaluator._eval\u001b[0;34m(self, problem, pop, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_eval\u001b[39m(\u001b[39mself\u001b[39m, problem, pop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 71\u001b[0m     out \u001b[39m=\u001b[39m problem\u001b[39m.\u001b[39;49mevaluate(pop\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     72\u001b[0m                            return_values_of\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_values_of,\n\u001b[1;32m     73\u001b[0m                            return_as_dictionary\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     74\u001b[0m                            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     76\u001b[0m     \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m out\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     77\u001b[0m         \u001b[39mif\u001b[39;00m val \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Github/MOBO_RFcons_LCD3D_6monomers/autooed/mobo/surrogate_problem.py:119\u001b[0m, in \u001b[0;36mSurrogateProblem.evaluate\u001b[0;34m(self, X, return_values_of, return_as_dictionary, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     out[val] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# calculate the output array - either elementwise or not. also consider the gradient\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate(X, out, \u001b[39m*\u001b[39;49margs, gradient\u001b[39m=\u001b[39;49mgradient, hessian\u001b[39m=\u001b[39;49mhessian, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    120\u001b[0m at_least2d(out)\n\u001b[1;32m    122\u001b[0m gradient_of \u001b[39m=\u001b[39m [key \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m out\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    123\u001b[0m                     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39md\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m key \u001b[39min\u001b[39;00m return_values_of \u001b[39mand\u001b[39;00m\n\u001b[1;32m    124\u001b[0m                     out\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39md\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m key) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    125\u001b[0m                     (\u001b[39mtype\u001b[39m(val) \u001b[39m==\u001b[39m autograd\u001b[39m.\u001b[39mnumpy\u001b[39m.\u001b[39mnumpy_boxes\u001b[39m.\u001b[39mArrayBox)]\n",
      "File \u001b[0;32m~/Github/MOBO_RFcons_LCD3D_6monomers/autooed/mobo/surrogate_problem.py:52\u001b[0m, in \u001b[0;36mSurrogateProblem._evaluate\u001b[0;34m(self, X, out, gradient, hessian, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m# evaluate cheap constraints by real problem\u001b[39;00m\n\u001b[1;32m     51\u001b[0m X_raw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformation\u001b[39m.\u001b[39mundo(X)\n\u001b[0;32m---> 52\u001b[0m out[\u001b[39m'\u001b[39m\u001b[39mG\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem\u001b[39m.\u001b[39mevaluate_constraint(x_raw) \u001b[39mfor\u001b[39;00m x_raw \u001b[39min\u001b[39;00m X_raw])\n",
      "File \u001b[0;32m~/Github/MOBO_RFcons_LCD3D_6monomers/autooed/mobo/surrogate_problem.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m# evaluate cheap constraints by real problem\u001b[39;00m\n\u001b[1;32m     51\u001b[0m X_raw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformation\u001b[39m.\u001b[39mundo(X)\n\u001b[0;32m---> 52\u001b[0m out[\u001b[39m'\u001b[39m\u001b[39mG\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproblem\u001b[39m.\u001b[39;49mevaluate_constraint(x_raw) \u001b[39mfor\u001b[39;00m x_raw \u001b[39min\u001b[39;00m X_raw])\n",
      "File \u001b[0;32m~/Github/MOBO_RFcons_LCD3D_6monomers/autooed/problem/predefined/printing3d.py:149\u001b[0m, in \u001b[0;36mprinting3d_dlp.evaluate_constraint\u001b[0;34m(self, x_)\u001b[0m\n\u001b[1;32m    146\u001b[0m RF_Tg \u001b[39m=\u001b[39m    RandomForestClassifier(max_depth\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, n_estimators\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    148\u001b[0m RF_print\u001b[39m.\u001b[39mfit(X, Y)\n\u001b[0;32m--> 149\u001b[0m RF_Tg\u001b[39m.\u001b[39;49mfit(X, Tg_group)\n\u001b[1;32m    151\u001b[0m \u001b[39m#print ('Printability accuracy on all data', RF_print.score(X, Y))\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m#print ('Tg accuracy on all data group 1 in range of [{}, {}] is: {}'.format(Tg_min, Tg_max, RF_Tg.score(X, Tg_group)))\u001b[39;00m\n\u001b[1;32m    153\u001b[0m x_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(x_, [\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msum (x_)])\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:474\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    463\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    465\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    466\u001b[0m ]\n\u001b[1;32m    468\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 474\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    475\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    476\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    477\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    478\u001b[0m )(\n\u001b[1;32m    479\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    480\u001b[0m         t,\n\u001b[1;32m    481\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    482\u001b[0m         X,\n\u001b[1;32m    483\u001b[0m         y,\n\u001b[1;32m    484\u001b[0m         sample_weight,\n\u001b[1;32m    485\u001b[0m         i,\n\u001b[1;32m    486\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    487\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    488\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    489\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    490\u001b[0m     )\n\u001b[1;32m    491\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    492\u001b[0m )\n\u001b[1;32m    494\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 185\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/tree/_classes.py:308\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNumber of labels=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m does not match number of samples=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         \u001b[39m%\u001b[39m (\u001b[39mlen\u001b[39m(y), n_samples)\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    307\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, DOUBLE)\n\u001b[1;32m    310\u001b[0m \u001b[39mif\u001b[39;00m expanded_class_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/utils/validation.py:1756\u001b[0m, in \u001b[0;36m_check_sample_weight\u001b[0;34m(sample_weight, X, dtype, copy, only_non_negative)\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1755\u001b[0m     dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[0;32m-> 1756\u001b[0m sample_weight \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1757\u001b[0m     sample_weight,\n\u001b[1;32m   1758\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1759\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1760\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1761\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1762\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1763\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msample_weight\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1764\u001b[0m )\n\u001b[1;32m   1765\u001b[0m \u001b[39mif\u001b[39;00m sample_weight\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1766\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSample weights must be 1D array or scalar\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/utils/validation.py:919\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    914\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    915\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    916\u001b[0m         )\n\u001b[1;32m    918\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 919\u001b[0m         _assert_all_finite(\n\u001b[1;32m    920\u001b[0m             array,\n\u001b[1;32m    921\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    922\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    923\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    924\u001b[0m         )\n\u001b[1;32m    926\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    927\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/envs/autooed/lib/python3.9/site-packages/sklearn/utils/validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39m# error message.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(over\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 122\u001b[0m     first_pass_isfinite \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39;49misfinite(xp\u001b[39m.\u001b[39;49msum(X))\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### preprocessing \n",
    "# printability as Y, Tg\n",
    "df = pd.read_csv('Yuchao_20220816.csv')\n",
    "Printability = np.asarray (df['Printability']).reshape(1,-1).T\n",
    "Y0 = Printability\n",
    "Y = np.where(Y0 == 'Y', 1, 0)\n",
    "Tg = np.asarray (df['Tg']).reshape(1,-1).T\n",
    "# put a very high value for Tg that are not printable, too brittle\n",
    "Tg[np.isnan(Tg)] = 200\n",
    "# group the Tg, we want it to be in range [10, 60]\n",
    "Tg_group = [1 if 10<i<60 else 0 for i in Tg]\n",
    "Tg_group = np.array(Tg_group)\n",
    "# read the 2 objectives\n",
    "toughness = np.asarray (df['Toughness(MJ/m3)']).reshape(1,-1).T\n",
    "toughness[np.isnan(toughness)] = 0\n",
    "strength = np.asarray (df['Tensile_Strength(MPa)']).reshape(1,-1).T\n",
    "strength[np.isnan(strength)] = 0\n",
    "# not using Tensile strain yet\n",
    "strain = np.asarray (df['Tensile_Strain_percentage']).reshape(1,-1).T\n",
    "strain[np.isnan(strain)] = 0\n",
    "\n",
    "# read the ratios of 6 monomers.\n",
    "A_Ratio = np.asarray (df['R1(HA)']).reshape(1,-1)\n",
    "B_Ratio = np.asarray (df['R2(IA)']).reshape(1,-1)\n",
    "C_Ratio = np.asarray (df['R3(NVP)']).reshape(1,-1)\n",
    "D_Ratio = np.asarray (df['R4(AA)']).reshape(1,-1)\n",
    "E_Ratio = np.asarray (df['R5(HEAA)']).reshape(1,-1)\n",
    "F_Ratio = np.asarray (df['R6(IBOA)']).reshape(1,-1)\n",
    "# did not consider F_Ratio, since we do not have it in optimization\n",
    "X_ = np.concatenate((A_Ratio.T, B_Ratio.T, C_Ratio.T, D_Ratio.T, E_Ratio.T), axis=1)\n",
    "X0 = np.concatenate((A_Ratio.T, B_Ratio.T, C_Ratio.T, D_Ratio.T, E_Ratio.T, F_Ratio.T), axis=1)\n",
    "\n",
    "# load monomers descriptors\n",
    "df = pd.read_csv('monomers_info.csv')\n",
    "energy = np.array (-df['dft_sp_E_RB3LYP'])\n",
    "pol_area = np.array (df['polar_surface_area'])\n",
    "complexity = np.array (df['complexity'])\n",
    "HAMW = np.array (df['HAMW'])\n",
    "solubility = np.array (df['solubility_sqrt_MJperm3'])\n",
    "solubility_d = np.array (df['solubility_dipole'])\n",
    "solubility_h = np.array (df['solubility_h'])\n",
    "solubility_p = np.array (df['solubility_p'])\n",
    "# multiply Ratios by their descriptors\n",
    "X_energy = np.multiply (X0, energy)\n",
    "#X_pol_area = np.multiply (X0, pol_area)\n",
    "X_complexity = np.multiply (X0, complexity)\n",
    "X_HAMW = np.multiply (X0, HAMW)\n",
    "X_solubility_d = np.multiply (X0, solubility_d)\n",
    "X_solubility_h = np.multiply (X0, solubility_h)\n",
    "X_solubility_p = np.multiply (X0, solubility_p)\n",
    "X = np.concatenate ((X_energy, X_complexity, X_HAMW, \n",
    "                    X_solubility_d, X_solubility_h, X_solubility_p), axis=1)\n",
    "\n",
    "# got more information about input varialbe may reduce the accuracy for \n",
    "# few samples, but it is informative for new samples.\n",
    "# The hyperparameters are fixed using one-leave-out in file \"leavout_CV_RF_printability_Tg.ipynb\"\n",
    "RF_print = RandomForestClassifier(random_state=0, \n",
    "                                  max_depth = 5, \n",
    "                                  n_estimators = 50)\n",
    "RF_print.fit(X, Y)\n",
    "Yhat = RF_print.predict(X)\n",
    "acc = accuracy_score(Y, Yhat)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "#print (RF_print.get_params(deep=True))\n",
    "RF_Tg = RandomForestClassifier(random_state=0, \n",
    "                                  max_depth = 5, \n",
    "                                  n_estimators = 50)\n",
    "RF_Tg.fit(X, Tg_group)\n",
    "Yhat = RF_Tg.predict(X)\n",
    "acc = accuracy_score(Tg_group, Yhat)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "#print (RF_Tg.get_params(deep=True))\n",
    "# RF.n_estimators = int (5 * RF.n_estimators)\n",
    "# RF2 = RF.fit(X_train[0:5,:], y_train[0:5])\n",
    "# pred = RF2.predict_proba(X_train)\n",
    "# print (RF2.score(X_train, y_train))\n",
    "# print (RF2.score(X_test, y_test))\n",
    "\n",
    "### Start the real optimization\n",
    "# Change the default values for new argument\n",
    "def get_general_args(args=None):\n",
    "    '''\n",
    "    General arguments: problem and algorithm description, experiment settings\n",
    "    '''\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--problem', type=str, default='printing3d_dlp', \n",
    "        help='optimization problem')\n",
    "    parser.add_argument('--algo', type=str, default='tsemo',\n",
    "        help='type of algorithm to use with some predefined arguments, or custom arguments')\n",
    "    parser.add_argument('--seed', type=int, default=10,\n",
    "        help='the specific seed to run')\n",
    "    parser.add_argument('--batch-size', type=int, default=1, \n",
    "        help='size of the batch in optimization')\n",
    "    parser.add_argument('--n-init-sample', type=int, default=0, \n",
    "        help='number of initial design samples')\n",
    "    parser.add_argument('--n-total-sample', type=int, default=50, \n",
    "        help='number of total design samples (budget)')\n",
    "\n",
    "    args, _ = parser.parse_known_args(args)\n",
    "    return args\n",
    "\n",
    "\n",
    "def get_surroagte_args(args=None):\n",
    "    '''\n",
    "    Arguments for fitting the surrogate model\n",
    "    '''\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--surrogate', type=str, \n",
    "        choices=['gp', 'nn', 'bnn'], default='gp', \n",
    "        help='type of the surrogate model')\n",
    "\n",
    "    args, _ = parser.parse_known_args(args)\n",
    "    return args\n",
    "\n",
    "\n",
    "def get_acquisition_args(args=None):\n",
    "    '''\n",
    "    Arguments for acquisition function\n",
    "    '''\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--acquisition', type=str,  \n",
    "        choices=['identity', 'pi', 'ei', 'ucb', 'ts'], default='ts', \n",
    "        help='type of the acquisition function')\n",
    "\n",
    "    args, _ = parser.parse_known_args(args)\n",
    "    return args\n",
    "\n",
    "\n",
    "def get_solver_args(args=None):\n",
    "    '''\n",
    "    Arguments for multi-objective solver\n",
    "    '''\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    # general solver\n",
    "    parser.add_argument('--solver', type=str, \n",
    "        choices=['nsga2', 'moead', 'parego', 'discovery', 'ga', 'cmaes'], default='nsga2', \n",
    "        help='type of the multiobjective solver')\n",
    "    parser.add_argument('--n-process', type=int, default=-1,\n",
    "        help='number of processes to be used for parallelization')\n",
    "\n",
    "    args, _ = parser.parse_known_args(args)\n",
    "    return args\n",
    "\n",
    "\n",
    "def get_selection_args(args=None):\n",
    "    '''\n",
    "    Arguments for sample selection\n",
    "    '''\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--selection', type=str,\n",
    "        choices=['direct', 'hvi', 'random', 'uncertainty'], default='hvi', \n",
    "        help='type of selection method for new batch')\n",
    "\n",
    "    args, _ = parser.parse_known_args(args)\n",
    "    return args\n",
    "\n",
    "def get_args():\n",
    "    '''\n",
    "    Get arguments from all components\n",
    "    You can specify args-path argument to directly load arguments from specified yaml file\n",
    "    '''\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--args-path', type=str, default=None,\n",
    "        help='used for directly loading arguments from path of argument file')\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    if args.args_path is None:\n",
    "\n",
    "        general_args = get_general_args()\n",
    "        surroagte_args = get_surroagte_args()\n",
    "        acquisition_args = get_acquisition_args()\n",
    "        solver_args = get_solver_args()\n",
    "        selection_args = get_selection_args()\n",
    "\n",
    "        module_cfg = {\n",
    "            'surrogate': vars(surroagte_args),\n",
    "            'acquisition': vars(acquisition_args),\n",
    "            'solver': vars(solver_args),\n",
    "            'selection': vars(selection_args),\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        \n",
    "        with open(args.args_path, 'r') as f:\n",
    "            all_args = yaml.load(f)\n",
    "        \n",
    "        general_args = Namespace(**all_args['general'])\n",
    "        module_cfg = all_args.copy()\n",
    "        module_cfg.pop('general')\n",
    "\n",
    "    return general_args, module_cfg\n",
    "\n",
    "\n",
    "# load arguments\n",
    "args, module_cfg = get_args()\n",
    "print (args.seed)\n",
    "# set random seed\n",
    "set_seed(args.seed)\n",
    "\n",
    "# build problem\n",
    "problem = build_problem(args.problem)\n",
    "print(problem)\n",
    "\n",
    "# build algorithm\n",
    "algorithm = build_algorithm(args.algo, problem, module_cfg)\n",
    "print(algorithm)\n",
    "\n",
    "# generate initial random samples\n",
    "X = generate_random_initial_samples(problem, args.n_init_sample)\n",
    "Y = np.array([problem.evaluate_objective(x) for x in X])\n",
    "print ('read X', X.shape)\n",
    "print ('read Y', Y.shape)\n",
    "\n",
    "# read the initial samples, X is 6 Ratios, Y is two objective: \n",
    "# Strength, Toughness.\n",
    "path = ['./Yuchao_20220816_X.csv', \n",
    "        './Yuchao_20220816_Y.csv']\n",
    "X, Y = load_provided_initial_samples(path)\n",
    "# we minimze the Objectives, so multiply -1\n",
    "Y = -Y\n",
    "print ('read X', X.shape)\n",
    "print ('read Y', Y.shape)\n",
    "\n",
    "X0 = X\n",
    "Y0 = Y\n",
    "# optimization\n",
    "while len(X) < args.n_total_sample:\n",
    "    start = time.time()\n",
    "    # propose design samples\n",
    "    X_next = algorithm.optimize(X, Y, X_busy=None, batch_size=2)\n",
    "    print (X_next)\n",
    "    print (time.time() - start)\n",
    "    # evaluate proposed samples\n",
    "    Y_next = np.array([problem.evaluate_objective(x) for x in X_next])\n",
    "    # combine into dataset\n",
    "    X = np.vstack([X, X_next])\n",
    "    Y = np.vstack([Y, Y_next])\n",
    "    for (x_next, y_next) in zip(X_next, Y_next):\n",
    "        while True:\n",
    "            try:\n",
    "                printability_new = int (input (\n",
    "                    \"ratios A-F {} sum {} Enter Printability 0or1: \".\n",
    "                     format(np.round(x_next, 2), np.sum(np.round(x_next, 2)))))\n",
    "            except ValueError:\n",
    "                print (\"printability is not read correctly\")\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        while True:\n",
    "            try:\n",
    "                 Tg_new = float (input (\n",
    "                  \"ratios A-F {} sum {} Enter Tg: \".\n",
    "                 format(np.round(x_next,2), np.sum(np.round(x_next, 2)))))\n",
    "            except ValueError:\n",
    "                print (\"Tg is not read correctly\")\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        new_printability_Tg = [list(np.round(x_next,2)), [1-np.sum(np.round(x_next,2))], printability_new, Tg_new]\n",
    "        new_sample = new_printability_Tg\n",
    "        new_printability_Tg = str(new_printability_Tg)\n",
    "        new_printability_Tg = new_printability_Tg.replace(\"[\", \"\")\n",
    "        new_printability_Tg = new_printability_Tg.replace(\"]\", \"\")\n",
    "        new_printability_Tg = new_printability_Tg + \"\\n\"\n",
    "        with open('printability_Tg.csv','a') as fd:\n",
    "            fd.write(new_printability_Tg)\n",
    "        new_sample.append(y_next[0])\n",
    "        new_sample.append(y_next[1])\n",
    "        new_sample = str(new_sample)\n",
    "        new_sample = new_sample.replace(\"[\", \"\")\n",
    "        new_sample = new_sample.replace(\"]\", \"\")\n",
    "        new_sample = new_sample + \"\\n\"\n",
    "        with open('new_evaluated.csv','a') as fd:\n",
    "            fd.write(new_sample)        \n",
    "    print(f'{len(X)}/{args.n_total_sample} complete')\n",
    "    print (time.time() - start)\n",
    "\n",
    "\n",
    "# plot\n",
    "Y_eval = Y[Y0.shape[0]:, :]\n",
    "plot_performance_space_diffcolor(Y0=-Y0, Y_eval=-Y_eval)\n",
    "plot_performance_metric(Y, problem.obj_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autooed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
